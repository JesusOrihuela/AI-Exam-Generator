# config.py

# Modelos LLM (no cambia comportamiento)
MODEL_SUMMARY = "gpt-4.1-mini"
MODEL_EXAM = "gpt-4.1-mini"

# Límite para cortar resúmenes en generación (antes estaba embebido en el worker)
MAX_SUMMARY_CHARS_FOR_GEN = 70000
